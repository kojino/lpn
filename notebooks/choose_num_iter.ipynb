{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kojin/anaconda/envs/ml/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from pathlib import Path\n",
    "from random import shuffle\n",
    "import random\n",
    "\n",
    "import argparse\n",
    "import copy\n",
    "import numpy as np\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import scipy.sparse as sp\n",
    "import sys\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\") \n",
    "from deeplp.models.deeplp_att import DeepLP_ATT\n",
    "from deeplp.models.deeplp_edge import DeepLP_Edge\n",
    "from deeplp.models.deeplp_wrbf import DeepLP_WRBF\n",
    "from deeplp.models.lp import LP\n",
    "from deeplp.utils import (calc_masks, create_seed_features, load_data,\n",
    "                          num_layers_dict, prepare_data, random_unlabel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approx_chunk(seq, num):\n",
    "    avg = len(seq) / float(num)\n",
    "    out = []\n",
    "    last = 0.0\n",
    "\n",
    "    while last < len(seq):\n",
    "        out.append(seq[int(last):int(last + avg)])\n",
    "        last += avg\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flip_cora\n"
     ]
    }
   ],
   "source": [
    "closed_accuracies = np.zeros((10)) \n",
    "iter_accuracies = np.zeros((10,10)) \n",
    "val_accuracies = np.zeros((10,10)) \n",
    "for p in [0.99]:\n",
    "#     for i,data in enumerate(['flip_cora','flip_dblp','flip_flickr','flip_imdb','flip_industry','linqs_citeseer','linqs_cora','linqs_pubmed']):\n",
    "    for i,data in enumerate(['flip_cora']):\n",
    "        print(data)\n",
    "        if data[:4] == 'flip':\n",
    "            model = 'att'\n",
    "        else:\n",
    "            model = 'edge'\n",
    "\n",
    "        for seed in range(10):\n",
    "            true_labels, edge_features, graph \\\n",
    "            = load_data(data,model=model)\n",
    "\n",
    "            labeled_indices, unlabeled_indices = \\\n",
    "                random_unlabel(true_labels,p,\n",
    "                               seed=seed)\n",
    "            num_nodes, num_classes = true_labels.shape\n",
    "\n",
    "            labels, is_labeled = calc_masks(true_labels, labeled_indices, unlabeled_indices)\n",
    "\n",
    "            for j in range(1,11):\n",
    "                final_accs = []\n",
    "\n",
    "                labeled_indices_copy = copy.copy(labeled_indices)\n",
    "                random.seed(seed)\n",
    "                shuffle(labeled_indices_copy)\n",
    "                cv_held_out_indices_list = approx_chunk(labeled_indices_copy, 5)\n",
    "\n",
    "\n",
    "                for k, cv_held_out_indices in enumerate(cv_held_out_indices_list):\n",
    "\n",
    "                    cv_labeled_indices = [index for index in labeled_indices if index not in cv_held_out_indices]\n",
    "                    cv_unlabeled_indices = np.delete(np.arange(true_labels.shape[0]),cv_labeled_indices)\n",
    "                    cv_labels, cv_is_labeled = calc_masks(true_labels, cv_labeled_indices, cv_unlabeled_indices)\n",
    "                    lp = LP()\n",
    "                    index = np.hstack([cv_held_out_indices,cv_unlabeled_indices])\n",
    "                    unlabeled_pred = lp.iter_sp(cv_labels,\n",
    "                                         graph,\n",
    "                                         cv_is_labeled,\n",
    "                                         10 * j,\n",
    "                                         index)\n",
    "\n",
    "                    y_pred = np.argmax(unlabeled_pred[:len(cv_held_out_indices)],axis=1)\n",
    "                    y_true = np.argmax(true_labels[cv_held_out_indices],axis=1)\n",
    "                    acc = np.mean(y_pred == y_true)\n",
    "                    final_accs.append(acc)\n",
    "                acc = np.mean(final_accs)\n",
    "                val_accuracies[seed,j-1] = acc\n",
    "\n",
    "                unlabeled_pred = lp.iter_sp(labels,\n",
    "                                     graph,\n",
    "                                     is_labeled,\n",
    "                                     10 * j,\n",
    "                                     unlabeled_indices)\n",
    "\n",
    "                y_pred = np.argmax(unlabeled_pred,axis=1)\n",
    "                y_true = np.argmax(true_labels[unlabeled_indices],axis=1)\n",
    "                acc = np.mean(y_pred == y_true)    \n",
    "                iter_accuracies[seed,j-1] = acc\n",
    "            lp = LP()\n",
    "            unlabeled_pred = lp.closed_sp(labels,\n",
    "                 graph,\n",
    "                 labeled_indices,\n",
    "                 unlabeled_indices)\n",
    "\n",
    "            y_pred = np.argmax(unlabeled_pred,axis=1)\n",
    "            y_true = np.argmax(true_labels[unlabeled_indices],axis=1)\n",
    "            acc = np.mean(y_pred == y_true)    \n",
    "            closed_accuracies[seed] = acc\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('t_lp_closed.csv',closed_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('t_lp_iter.csv',iter_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('t_lp_val.csv',val_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.52,  0.36,  0.4 ,  0.4 ,  0.4 ,  0.36,  0.32,  0.32,  0.28,\n",
       "         0.28],\n",
       "       [ 0.6 ,  0.6 ,  0.6 ,  0.6 ,  0.6 ,  0.6 ,  0.6 ,  0.  ,  0.  ,  0.  ],\n",
       "       [ 0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ],\n",
       "       [ 0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ],\n",
       "       [ 0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ],\n",
       "       [ 0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ],\n",
       "       [ 0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ],\n",
       "       [ 0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ],\n",
       "       [ 0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ],\n",
       "       [ 0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.584     ,  0.576     ,  0.576     ,  0.572     ,  0.56      ,\n",
       "         0.54      ,  0.524     ,  0.516     ,  0.496     ,  0.496     ],\n",
       "       [ 0.64090909,  0.65436364,  0.65581818,  0.64672727,  0.64127273,\n",
       "         0.62490909,  0.62709091,  0.61963636,  0.60872727,  0.59381818],\n",
       "       [ 0.66      ,  0.65875   ,  0.6325    ,  0.60625   ,  0.6025    ,\n",
       "         0.5875    ,  0.57375   ,  0.57      ,  0.55875   ,  0.55125   ],\n",
       "       [ 0.48333333,  0.48666667,  0.47666667,  0.47      ,  0.48      ,\n",
       "         0.48      ,  0.48      ,  0.48      ,  0.48      ,  0.48      ],\n",
       "       [ 0.105     ,  0.1       ,  0.095     ,  0.10666667,  0.10666667,\n",
       "         0.10666667,  0.10666667,  0.10666667,  0.10166667,  0.10166667],\n",
       "       [ 0.399     ,  0.399     ,  0.385     ,  0.394     ,  0.394     ,\n",
       "         0.398     ,  0.398     ,  0.407     ,  0.412     ,  0.408     ],\n",
       "       [ 0.54      ,  0.54      ,  0.536     ,  0.54      ,  0.54      ,\n",
       "         0.524     ,  0.508     ,  0.488     ,  0.456     ,  0.452     ],\n",
       "       [ 0.7610641 ,  0.76614103,  0.76164103,  0.75657692,  0.74747436,\n",
       "         0.74292308,  0.73633333,  0.73332051,  0.72728205,  0.72021795]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(val_accuracies,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.37552846,  0.67117886,  0.70565041,  0.65443089,  0.69378049,\n",
       "        0.61743902,  0.5499187 ,  0.63044715,  0.66886179,  0.49804878])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(iter_accuracies,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.44796748,  0.42804878,  0.41747967,  0.39674797,  0.38577236,\n",
       "         0.36829268,  0.34756098,  0.33739837,  0.32520325,  0.30081301],\n",
       "       [ 0.67682927,  0.68292683,  0.68617886,  0.68658537,  0.68617886,\n",
       "         0.67886179,  0.66747967,  0.65894309,  0.64715447,  0.64065041],\n",
       "       [ 0.67601626,  0.7101626 ,  0.71544715,  0.71666667,  0.71585366,\n",
       "         0.71422764,  0.71056911,  0.70609756,  0.6995935 ,  0.69186992],\n",
       "       [ 0.59837398,  0.63780488,  0.64674797,  0.65934959,  0.66422764,\n",
       "         0.66788618,  0.66747967,  0.66747967,  0.66829268,  0.66666667],\n",
       "       [ 0.67073171,  0.68821138,  0.69593496,  0.70162602,  0.70406504,\n",
       "         0.70487805,  0.69837398,  0.69471545,  0.69065041,  0.68861789],\n",
       "       [ 0.6199187 ,  0.62804878,  0.62439024,  0.62276423,  0.62195122,\n",
       "         0.6199187 ,  0.61707317,  0.61300813,  0.60813008,  0.59918699],\n",
       "       [ 0.57154472,  0.57642276,  0.57439024,  0.57560976,  0.56544715,\n",
       "         0.55203252,  0.53739837,  0.52560976,  0.51504065,  0.50569106],\n",
       "       [ 0.6101626 ,  0.62886179,  0.63780488,  0.64105691,  0.64349593,\n",
       "         0.64105691,  0.63577236,  0.6304878 ,  0.62235772,  0.61341463],\n",
       "       [ 0.66829268,  0.67276423,  0.67560976,  0.67357724,  0.67154472,\n",
       "         0.66869919,  0.66829268,  0.66747967,  0.66544715,  0.65691057],\n",
       "       [ 0.60203252,  0.59105691,  0.55243902,  0.52154472,  0.48943089,\n",
       "         0.46869919,  0.45406504,  0.43902439,  0.43292683,  0.42926829]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iter_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.58333333,  0.575     ,  0.58166667,  0.56      ,  0.54666667,\n",
       "         0.52      ,  0.51666667,  0.50833333,  0.505     ,  0.50166667],\n",
       "       [ 0.66484848,  0.66878788,  0.67818182,  0.66636364,  0.65393939,\n",
       "         0.65333333,  0.64787879,  0.64606061,  0.63969697,  0.62909091],\n",
       "       [ 0.68      ,  0.66      ,  0.63625   ,  0.61125   ,  0.5975    ,\n",
       "         0.58875   ,  0.5775    ,  0.56875   ,  0.5625    ,  0.55375   ],\n",
       "       [ 0.47727273,  0.47272727,  0.46363636,  0.45909091,  0.46818182,\n",
       "         0.46818182,  0.47727273,  0.47727273,  0.47727273,  0.47727273],\n",
       "       [ 0.105     ,  0.105     ,  0.105     ,  0.115     ,  0.115     ,\n",
       "         0.115     ,  0.115     ,  0.115     ,  0.11      ,  0.11      ],\n",
       "       [ 0.36969697,  0.37878788,  0.36515152,  0.37424242,  0.37575758,\n",
       "         0.39242424,  0.3969697 ,  0.39242424,  0.40151515,  0.40151515],\n",
       "       [ 0.56833333,  0.57      ,  0.565     ,  0.56      ,  0.545     ,\n",
       "         0.53      ,  0.51      ,  0.495     ,  0.485     ,  0.47666667],\n",
       "       [ 0.76452632,  0.76610526,  0.76352632,  0.75947368,  0.7545    ,\n",
       "         0.75147368,  0.74294737,  0.73939474,  0.73489474,  0.73189474]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(val_accuracies,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "# pkl.dump(accuracies,open('lp_acc.p','wb')\n",
    "# pkl.dump(val_accuracies,open('lp_val_acc.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = pkl.load(open('lp_acc.p','rb'))\n",
    "val_accuracies = pkl.load(open('lp_val_acc.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.584     ,  0.576     ,  0.576     ,  0.572     ,  0.56      ,\n",
       "         0.54      ,  0.524     ,  0.516     ,  0.496     ,  0.496     ],\n",
       "       [ 0.64090909,  0.65436364,  0.65581818,  0.64672727,  0.64127273,\n",
       "         0.62490909,  0.62709091,  0.61963636,  0.60872727,  0.59381818],\n",
       "       [ 0.66      ,  0.65875   ,  0.6325    ,  0.60625   ,  0.6025    ,\n",
       "         0.5875    ,  0.57375   ,  0.57      ,  0.55875   ,  0.55125   ],\n",
       "       [ 0.48333333,  0.48666667,  0.47666667,  0.47      ,  0.48      ,\n",
       "         0.48      ,  0.48      ,  0.48      ,  0.48      ,  0.48      ],\n",
       "       [ 0.105     ,  0.1       ,  0.095     ,  0.10666667,  0.10666667,\n",
       "         0.10666667,  0.10666667,  0.10666667,  0.10166667,  0.10166667],\n",
       "       [ 0.399     ,  0.399     ,  0.385     ,  0.394     ,  0.394     ,\n",
       "         0.398     ,  0.398     ,  0.407     ,  0.412     ,  0.408     ],\n",
       "       [ 0.54      ,  0.54      ,  0.536     ,  0.54      ,  0.54      ,\n",
       "         0.524     ,  0.508     ,  0.488     ,  0.456     ,  0.452     ],\n",
       "       [ 0.7610641 ,  0.76614103,  0.76164103,  0.75657692,  0.74747436,\n",
       "         0.74292308,  0.73633333,  0.73332051,  0.72728205,  0.72021795]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_accuracies.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.61418699,  0.62443089,  0.62264228,  0.61955285,  0.61479675,\n",
       "         0.60845528,  0.6004065 ,  0.59402439,  0.58747967,  0.57930894],\n",
       "       [ 0.70087452,  0.7156654 ,  0.71644487,  0.70980989,  0.70391635,\n",
       "         0.69880228,  0.6938403 ,  0.68813688,  0.68311787,  0.67855513],\n",
       "       [ 0.66822963,  0.65881384,  0.633101  ,  0.60931441,  0.59114181,\n",
       "         0.57906476,  0.56820428,  0.55885186,  0.5497909 ,  0.54195919],\n",
       "       [ 0.55072072,  0.53333333,  0.52657658,  0.52198198,  0.52081081,\n",
       "         0.51963964,  0.51873874,  0.51783784,  0.51774775,  0.51711712],\n",
       "       [ 0.2130946 ,  0.21042223,  0.20737573,  0.20897916,  0.20994121,\n",
       "         0.21084981,  0.21074292,  0.21052913,  0.20983431,  0.20935329],\n",
       "       [ 0.52725096,  0.5362069 ,  0.53922414,  0.54300766,  0.54310345,\n",
       "         0.5427682 ,  0.5414272 ,  0.54195402,  0.54171456,  0.5414751 ],\n",
       "       [ 0.62995935,  0.6402439 ,  0.64308943,  0.63776423,  0.62930894,\n",
       "         0.61837398,  0.60699187,  0.59817073,  0.59256098,  0.5852439 ],\n",
       "       [ 0.73901839,  0.74314258,  0.74035555,  0.7352016 ,  0.72950971,\n",
       "         0.72362314,  0.71843332,  0.71368923,  0.70875557,  0.70529228]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
